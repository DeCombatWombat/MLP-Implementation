from numpy import exp, array, random, dot, sum


class NeuronLayer():
    def __init__(self, number_of_neurons, number_of_inputs_per_neuron):
        self.synaptic_weights = 2 * random.random((number_of_inputs_per_neuron, number_of_neurons)) - 1


class NeuralNetwork():
    def __init__(self, layer1, layer2):
        self.layer1 = layer1
        self.layer2 = layer2

    # The Sigmoid function, which describes an S shaped curve
    def __sigmoid(self, x):
        return 1 / (1 + exp(-x))

    # The derivative of the Sigmoid function
    def __sigmoid_derivative(self, x):
        return x * (1 - x)

    # We train the neural network through a process of trial and error
    def train(self, training_set_inputs, training_set_outputs, number_of_training_iterations):
        for iteration in range(number_of_training_iterations):
            # Pass the training set through our neural network
            output_from_layer_1, output_from_layer_2 = self.think(training_set_inputs)

            # Calculate the error for layer 2
            layer2_error = training_set_outputs - output_from_layer_2

            layer2_error_square = layer2_error * layer2_error
            MSE = sum(layer2_error_square) / len(layer2_error_square)

            layer2_delta = layer2_error * self.__sigmoid_derivative(output_from_layer_2)

            with open('csvfile.csv', 'a') as file:
                file.write(str(MSE))
                file.write('\n')

            # Calculate the error for layer 1
            layer1_error = layer2_delta.dot(self.layer2.synaptic_weights.T)
            layer1_delta = layer1_error * self.__sigmoid_derivative(output_from_layer_1)

            # Calculate how much to adjust the weights by
            layer1_adjustment = training_set_inputs.T.dot(layer1_delta)
            layer2_adjustment = output_from_layer_1.T.dot(layer2_delta)

            # Adjust the weights
            self.layer1.synaptic_weights += layer1_adjustment
            self.layer2.synaptic_weights += layer2_adjustment

    def think(self, inputs):
        output_from_layer1 = self.__sigmoid(dot(inputs, self.layer1.synaptic_weights))
        output_from_layer2 = self.__sigmoid(dot(output_from_layer1, self.layer2.synaptic_weights))
        return output_from_layer1, output_from_layer2

    def thinksquare(self, inputs):
        output_from_layer1 = self.__sigmoid(dot(inputs, self.layer1.synaptic_weights))
        output_from_layer2 = self.__sigmoid(dot(output_from_layer1, self.layer2.synaptic_weights))

        with open('unitsquare.csv', 'a') as file:
            for num in output_from_layer2:
                file.write(str(float(num)))
                file.write(',')
                file.write('\n')

        return output_from_layer1, output_from_layer2

    # The neural network prints its weights
    def print_weights(self):
        print("Layer 1 (4 neurons, each with 3 inputs): ")
        print(self.layer1.synaptic_weights)
        print("Layer 2 (1 neuron, with 4 inputs):")
        print(self.layer2.synaptic_weights)

if __name__ == "__main__":

    #Seed the random number generator
    random.seed(1)

    # Create layer 1 (2 neurons, each with 3 inputs)
    layer1 = NeuronLayer(2, 3)

    # Create layer 2 (a single neuron with 2 inputs)
    layer2 = NeuronLayer(1, 2)

    # Combine the layers to create a neural network
    neural_network = NeuralNetwork(layer1, layer2)

    print("Stage 1) Random starting synaptic weights: ")
    neural_network.print_weights()

    # The training set. We have 16 examples, each consisting of 3 input values
    # and 1 output value.
    training_set_inputs_16 = array([[-0.310691, 0.0164278, -1], [-0.309003, 0.898471, -1], [1.25774, -0.231735, -1], [1.31959, 0.82952, -1], [-0.0897083, -1.02045, -1], [-0.457115, 1.84369, -1], [1.42524, 0.111823, -1], [1.43962, 0.28365, -1], [-0.21377, 0.0759174, -1], [-0.16744, 0.985518, -1], [0.579612, 0.584378, -1], [1.90558, 0.434351, -1], [0.442017, 0.35245, -1], [0.204012, -0.0194183, -1], [1.75664, -0.336488, -1], [0.584128,  1.45608, -1]])
    training_set_inputs_32 = array([[-0.1968699036014784,-0.24156862647955774, -1], [0.22329856831879277,1.223228216533919, -1], [0.579339365713415,0.11980213518010464, -1], [1.3104792626172936,0.7949323884649933, -1], [-0.19387553132490845,0.08684541879065065, -1], [-0.4037709434588513,0.5949784407610791, -1], [0.878434556622085,-0.21861563746114848, -1], [1.0390689424643087,1.4983360704748478, -1], [-0.1051121066548811,0.2269497524589294, -1], [-0.3250552488724252,0.9765157672486138, -1], [1.1188235028852738,-0.20772880374361113, -1], [0.8617286535849392,0.865645559349505, -1], [0.3922817982115514,-0.3814228478496962, -1], [0.16283212666247296,1.0152396121801344, -1], [0.7801881977409554,0.0603401299139734, -1], [0.6755116519585587,0.7089495644349284, -1], [0.16896920145440505,-0.12148746364799502, -1], [0.37066454129231785,1.0804618965308315, -1], [1.1099882467838238,0.2713578958923586, -1], [0.7960382096854655,0.7832333690860968, -1], [0.032380812126771116,-0.4357971641674646, -1], [0.031829984693244835,1.0105994804074925, -1], [0.9812117987857324,-0.1914567591035158, -1], [0.6990429397841718,0.9124868544931323, -1], [-0.01794061594248289,0.3277846604565663, -1], [0.3228857755770521,1.2506025035596537, -1], [0.7520745320932469,-0.38697675893756556, -1], [1.0075856075577394,1.44749737593738, -1], [0.16332898546695176,-0.463563306753558, -1], [0.30607226938341053,0.8963285644658072, -1], [1.1146943512013847,0.3834013735886424, -1], [1.100921655630706,1.1703451686238067, -1]])
    training_set_inputs_64 = array([[0.3962652667474389,0.5968110675975936, -1], [-0.00537481679725251,0.7977764074701834, -1], [0.7933315921803891,0.005371877230382726, -1], [0.5786165338879448,1.1616690003992283, -1], [0.05136615820114465,0.07960625923438723, -1], [-0.2502608010599344,1.2567579291722781, -1], [1.2236603578338483,-0.019987002708465013, -1], [1.0779004036427386,1.1332251815484298, -1], [0.011635190969474664,-0.2077478985789271, -1], [-0.1338487600238261,1.1122908966513207, -1], [1.4606963464298883,0.515784438570448, -1], [0.5529071995844757,0.9957459850038888, -1], [0.19988142278539064,-0.10335433615167913, -1], [-0.5517322732620866,0.7382303015920866, -1], [1.0451308863898607,-0.22433871672116842, -1], [0.6962420111363165,1.3698500262054432, -1], [-0.5120083016978016,-0.0420596878124394, -1], [0.08498077123623905,0.8726139494458777, -1], [0.7667465039952344,0.18395235138637137, -1], [1.0205926138463637,0.9072068246526135, -1], [-0.2991765930855061,0.2813565729777045, -1], [0.36672021702059027,0.8134186207609798, -1], [0.9858397907134666,-0.22360320886217921, -1], [1.0233013289535098,1.1243479971580577, -1], [0.41374316645726716,-0.3449399040239867, -1], [-0.38268837299778735,0.7033919538726547, -1], [1.2995967271222113,0.44914896551073064, -1], [0.8567471598320646,1.103997452397169, -1], [-0.1026607308899695,-0.0313036987828696, -1], [0.04545385853195436,1.3308212328405784, -1], [1.0077823216924398,0.4411429263790198, -1], [1.0023951955746433,0.5407507611606993, -1], [0.0873793488767393,-0.3592147507139014, -1], [0.29053205378478164,1.0198057924866122, -1], [0.6232074654758795,-0.36054786013273277, -1], [0.8589369787054515,0.4281099478568834, -1], [0.2736922288732961,-0.2175161811679852, -1], [-0.1801900407849601,1.1987563505294374, -1], [0.46372329614364083,-0.008153144289493675, -1], [0.49850558085990626,0.9043523447720683, -1], [0.11943381632218888,0.3475624794951638, -1], [-0.5354088967377115,0.7267839447457211, -1], [0.8033902017294628,0.33402956731559524, -1], [1.0016252333800686,0.6659907148190845, -1], [-0.13199815505994514,-0.24106287698292925, -1], [0.24700883760808845,0.8162405495743323, -1], [0.7311539296305576,-0.2111117623428699, -1], [0.14789298914891702,0.964470995414885, -1], [0.06537730567212494,-0.30631901767310166, -1], [0.12766825207776009,1.1880540343190522, -1], [1.1834425240609043,0.1899053558334906, -1], [0.7379910820364106,1.1669715748534328, -1], [-0.19138900956628804,0.16132010054913382, -1], [0.04448149957889517,1.1645044320364797, -1], [0.8933800745852869,-0.18913983280961713, -1], [0.8439414137155248,1.0472186033526631, -1], [-0.42437108238792104,0.055111876672798654, -1], [-0.1058949747694005,0.8865670658755086, -1], [0.931880611598591,-0.08506693809093896, -1], [1.3779428709804946,0.7890419310412051, -1], [0.24570948136720758,0.1666995193297233, -1], [-0.02812936012724475,1.2529065966654427, -1], [1.0332717480664022,0.08799366137485214, -1], [1.289819861432299,1.0954620001999906, -1]])

    training_set_outputs_16 = array([[0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0]]).T
    training_set_outputs_32 = array([[0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0]]).T
    training_set_outputs_64 = array([[0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0]]).T


    unit_square = array([[0.0,0.0, -1],[0.0,0.050, -1],[0.0,0.10, -1],[0.0,0.15, -1],[0.0,0.20, -1],[0.0,0.25, -1],[0.0,0.30, -1],[0.0,0.35, -1],[0.0,0.40, -1],[0.0,0.45, -1],[0.0,0.50, -1],[0.0,0.55, -1],[0.0,0.60, -1],[0.0,0.65, -1],[0.0,0.70, -1],[0.0,0.75, -1],[0.0,0.80, -1],[0.0,0.85, -1],[0.0,0.90, -1],[0.0,0.95, -1],[0.0,1.0, -1],[0.050,0.0, -1],[0.050,0.050, -1],[0.050,0.10, -1],[0.050,0.15, -1],[0.050,0.20, -1],[0.050,0.25, -1],[0.050,0.30, -1],[0.050,0.35, -1],[0.050,0.40, -1],[0.050,0.45, -1],[0.050,0.50, -1],[0.050,0.55, -1],[0.050,0.60, -1],[0.050,0.65, -1],[0.050,0.70, -1],[0.050,0.75, -1],[0.050,0.80, -1],[0.050,0.85, -1],[0.050,0.90, -1],[0.050,0.95, -1],[0.050,1.0, -1],[0.10,0.0, -1],[0.10,0.050, -1],[0.10,0.10, -1],[0.10,0.15, -1],[0.10,0.20, -1],[0.10,0.25, -1],[0.10,0.30, -1],[0.10,0.35, -1],[0.10,0.40, -1],[0.10,0.45, -1],[0.10,0.50, -1],[0.10,0.55, -1],[0.10,0.60, -1],[0.10,0.65, -1],[0.10,0.70, -1],[0.10,0.75, -1],[0.10,0.80, -1],[0.10,0.85, -1],[0.10,0.90, -1],[0.10,0.95, -1],[0.10,1.0, -1],[0.15,0.0, -1],[0.15,0.050, -1],[0.15,0.10, -1],[0.15,0.15, -1],[0.15,0.20, -1],[0.15,0.25, -1],[0.15,0.30, -1],[0.15,0.35, -1],[0.15,0.40, -1],[0.15,0.45, -1],[0.15,0.50, -1],[0.15,0.55, -1],[0.15,0.60, -1],[0.15,0.65, -1],[0.15,0.70, -1],[0.15,0.75, -1],[0.15,0.80, -1],[0.15,0.85, -1],[0.15,0.90, -1],[0.15,0.95, -1],[0.15,1.0, -1],[0.20,0.0, -1],[0.20,0.050, -1],[0.20,0.10, -1],[0.20,0.15, -1],[0.20,0.20, -1],[0.20,0.25, -1],[0.20,0.30, -1],[0.20,0.35, -1],[0.20,0.40, -1],[0.20,0.45, -1],[0.20,0.50, -1],[0.20,0.55, -1],[0.20,0.60, -1],[0.20,0.65, -1],[0.20,0.70, -1],[0.20,0.75, -1],[0.20,0.80, -1],[0.20,0.85, -1],[0.20,0.90, -1],[0.20,0.95, -1],[0.20,1.0, -1],[0.25,0.0, -1],[0.25,0.050, -1],[0.25,0.10, -1],[0.25,0.15, -1],[0.25,0.20, -1],[0.25,0.25, -1],[0.25,0.30, -1],[0.25,0.35, -1],[0.25,0.40, -1],[0.25,0.45, -1],[0.25,0.50, -1],[0.25,0.55, -1],[0.25,0.60, -1],[0.25,0.65, -1],[0.25,0.70, -1],[0.25,0.75, -1],[0.25,0.80, -1],[0.25,0.85, -1],[0.25,0.90, -1],[0.25,0.95, -1],[0.25,1.0, -1],[0.30,0.0, -1],[0.30,0.050, -1],[0.30,0.10, -1],[0.30,0.15, -1],[0.30,0.20, -1],[0.30,0.25, -1],[0.30,0.30, -1],[0.30,0.35, -1],[0.30,0.40, -1],[0.30,0.45, -1],[0.30,0.50, -1],[0.30,0.55, -1],[0.30,0.60, -1],[0.30,0.65, -1],[0.30,0.70, -1],[0.30,0.75, -1],[0.30,0.80, -1],[0.30,0.85, -1],[0.30,0.90, -1],[0.30,0.95, -1],[0.30,1.0, -1],[0.35,0.0, -1],[0.35,0.050, -1],[0.35,0.10, -1],[0.35,0.15, -1],[0.35,0.20, -1],[0.35,0.25, -1],[0.35,0.30, -1],[0.35,0.35, -1],[0.35,0.40, -1],[0.35,0.45, -1],[0.35,0.50, -1],[0.35,0.55, -1],[0.35,0.60, -1],[0.35,0.65, -1],[0.35,0.70, -1],[0.35,0.75, -1],[0.35,0.80, -1],[0.35,0.85, -1],[0.35,0.90, -1],[0.35,0.95, -1],[0.35,1.0, -1],[0.40,0.0, -1],[0.40,0.050, -1],[0.40,0.10, -1],[0.40,0.15, -1],[0.40,0.20, -1],[0.40,0.25, -1],[0.40,0.30, -1],[0.40,0.35, -1],[0.40,0.40, -1],[0.40,0.45, -1],[0.40,0.50, -1],[0.40,0.55, -1],[0.40,0.60, -1],[0.40,0.65, -1],[0.40,0.70, -1],[0.40,0.75, -1],[0.40,0.80, -1],[0.40,0.85, -1],[0.40,0.90, -1],[0.40,0.95, -1],[0.40,1.0, -1],[0.45,0.0, -1],[0.45,0.050, -1],[0.45,0.10, -1],[0.45,0.15, -1],[0.45,0.20, -1],[0.45,0.25, -1],[0.45,0.30, -1],[0.45,0.35, -1],[0.45,0.40, -1],[0.45,0.45, -1],[0.45,0.50, -1],[0.45,0.55, -1],[0.45,0.60, -1],[0.45,0.65, -1],[0.45,0.70, -1],[0.45,0.75, -1],[0.45,0.80, -1],[0.45,0.85, -1],[0.45,0.90, -1],[0.45,0.95, -1],[0.45,1.0, -1],[0.50,0.0, -1],[0.50,0.050, -1],[0.50,0.10, -1],[0.50,0.15, -1],[0.50,0.20, -1],[0.50,0.25, -1],[0.50,0.30, -1],[0.50,0.35, -1],[0.50,0.40, -1],[0.50,0.45, -1],[0.50,0.50, -1],[0.50,0.55, -1],[0.50,0.60, -1],[0.50,0.65,
-1],[0.50,0.70, -1],[0.50,0.75, -1],[0.50,0.80, -1],[0.50,0.85, -1],[0.50,0.90, -1],[0.50,0.95, -1],[0.50,1.0, -1],[0.55,0.0, -1],[0.55,0.050, -1],[0.55,0.10, -1],[0.55,0.15, -1],[0.55,0.20, -1],[0.55,0.25, -1],[0.55,0.30, -1],[0.55,0.35, -1],[0.55,0.40, -1],[0.55,0.45, -1],[0.55,0.50, -1],[0.55,0.55, -1],[0.55,0.60, -1],[0.55,0.65, -1],[0.55,0.70, -1],[0.55,0.75, -1],[0.55,0.80, -1],[0.55,0.85, -1],[0.55,0.90, -1],[0.55,0.95, -1],[0.55,1.0, -1],[0.60,0.0, -1],[0.60,0.050, -1],[0.60,0.10, -1],[0.60,0.15,
-1],[0.60,0.20, -1],[0.60,0.25, -1],[0.60,0.30, -1],[0.60,0.35, -1],[0.60,0.40, -1],[0.60,0.45, -1],[0.60,0.50, -1],[0.60,0.55, -1],[0.60,0.60, -1],[0.60,0.65, -1],[0.60,0.70, -1],[0.60,0.75, -1],[0.60,0.80, -1],[0.60,0.85, -1],[0.60,0.90, -1],[0.60,0.95, -1],[0.60,1.0, -1],[0.65,0.0, -1],[0.65,0.050, -1],[0.65,0.10, -1],[0.65,0.15, -1],[0.65,0.20, -1],[0.65,0.25, -1],[0.65,0.30, -1],[0.65,0.35, -1],[0.65,0.40, -1],[0.65,0.45, -1],[0.65,0.50, -1],[0.65,0.55, -1],[0.65,0.60, -1],[0.65,0.65, -1],[0.65,0.70, -1],[0.65,0.75, -1],[0.65,0.80, -1],[0.65,0.85, -1],[0.65,0.90, -1],[0.65,0.95, -1],[0.65,1.0, -1],[0.70,0.0, -1],[0.70,0.050, -1],[0.70,0.10, -1],[0.70,0.15, -1],[0.70,0.20, -1],[0.70,0.25, -1],[0.70,0.30, -1],[0.70,0.35, -1],[0.70,0.40, -1],[0.70,0.45, -1],[0.70,0.50, -1],[0.70,0.55, -1],[0.70,0.60, -1],[0.70,0.65, -1],[0.70,0.70, -1],[0.70,0.75, -1],[0.70,0.80, -1],[0.70,0.85, -1],[0.70,0.90, -1],[0.70,0.95, -1],[0.70,1.0, -1],[0.75,0.0, -1],[0.75,0.050, -1],[0.75,0.10, -1],[0.75,0.15, -1],[0.75,0.20, -1],[0.75,0.25, -1],[0.75,0.30, -1],[0.75,0.35, -1],[0.75,0.40, -1],[0.75,0.45, -1],[0.75,0.50, -1],[0.75,0.55, -1],[0.75,0.60, -1],[0.75,0.65, -1],[0.75,0.70, -1],[0.75,0.75, -1],[0.75,0.80, -1],[0.75,0.85, -1],[0.75,0.90, -1],[0.75,0.95, -1],[0.75,1.0, -1],[0.80,0.0, -1],[0.80,0.050, -1],[0.80,0.10, -1],[0.80,0.15, -1],[0.80,0.20, -1],[0.80,0.25, -1],[0.80,0.30, -1],[0.80,0.35, -1],[0.80,0.40, -1],[0.80,0.45, -1],[0.80,0.50, -1],[0.80,0.55, -1],[0.80,0.60, -1],[0.80,0.65, -1],[0.80,0.70, -1],[0.80,0.75, -1],[0.80,0.80, -1],[0.80,0.85, -1],[0.80,0.90, -1],[0.80,0.95, -1],[0.80,1.0, -1],[0.85,0.0, -1],[0.85,0.050, -1],[0.85,0.10, -1],[0.85,0.15, -1],[0.85,0.20, -1],[0.85,0.25, -1],[0.85,0.30, -1],[0.85,0.35, -1],[0.85,0.40, -1],[0.85,0.45, -1],[0.85,0.50, -1],[0.85,0.55, -1],[0.85,0.60, -1],[0.85,0.65, -1],[0.85,0.70, -1],[0.85,0.75, -1],[0.85,0.80, -1],[0.85,0.85, -1],[0.85,0.90, -1],[0.85,0.95, -1],[0.85,1.0, -1],[0.90,0.0, -1],[0.90,0.050, -1],[0.90,0.10, -1],[0.90,0.15, -1],[0.90,0.20, -1],[0.90,0.25, -1],[0.90,0.30, -1],[0.90,0.35, -1],[0.90,0.40, -1],[0.90,0.45, -1],[0.90,0.50, -1],[0.90,0.55, -1],[0.90,0.60, -1],[0.90,0.65, -1],[0.90,0.70, -1],[0.90,0.75, -1],[0.90,0.80, -1],[0.90,0.85, -1],[0.90,0.90, -1],[0.90,0.95, -1],[0.90,1.0, -1],[0.95,0.0, -1],[0.95,0.050, -1],[0.95,0.10, -1],[0.95,0.15, -1],[0.95,0.20, -1],[0.95,0.25, -1],[0.95,0.30, -1],[0.95,0.35, -1],[0.95,0.40, -1],[0.95,0.45, -1],[0.95,0.50, -1],[0.95,0.55, -1],[0.95,0.60, -1],[0.95,0.65, -1],[0.95,0.70, -1],[0.95,0.75, -1],[0.95,0.80, -1],[0.95,0.85, -1],[0.95,0.90, -1],[0.95,0.95, -1],[0.95,1.0, -1],[1.0,0.0, -1],[1.0,0.050, -1],[1.0,0.10, -1],[1.0,0.15, -1],[1.0,0.20, -1],[1.0,0.25, -1],[1.0,0.30, -1],[1.0,0.35, -1],[1.0,0.40, -1],[1.0,0.45, -1],[1.0,0.50, -1],[1.0,0.55, -1],[1.0,0.60, -1],[1.0,0.65, -1],[1.0,0.70, -1],[1.0,0.75, -1],[1.0,0.80, -1],[1.0,0.85, -1],[1.0,0.90, -1],[1.0,0.95, -1],[1.0,1.0, -1]])

    test_diff_vecs = array([[0.030872814289038836,0.3562035585342075, -1], [-0.33979986570869164,1.0003544860099929, -1], [0.8569357056745277,-0.1250107181690235, -1], [0.9073599305655257,0.9494332147997222, -1], [0.4811697142649102,0.0120048295059474, -1], [0.35269688698946156,0.8661274122455136, -1], [1.0672928959343664,-0.26079876008695485, -1], [0.9921438337349809,0.8022976426501819, -1], [-0.24850395427930128,0.2695272265444692, -1], [-0.24689444028152852,0.7573241678627196, -1], [1.1346043430211126,0.04246671779932672, -1], [0.606073958190287,1.0446272312748077, -1], [-8.824165726340859E-4,-0.1752290346989153, -1], [0.1631886485963656,0.7737744252274138, -1], [1.0689316228052528,0.0695340453086899, -1], [0.7534095340272371,0.9237165260208413, -1], [0.09305825778364525,0.049615403299920674, -1], [-0.017955622216579085,0.9202225556902629, -1], [0.6787160487713293,0.1856776382087908, -1], [1.1396135782658012,1.0485966139348044, -1], [-0.03277803695437974,0.39752629065310324, -1], [0.1999004952557223,0.8171062619511014, -1], [0.8867272045641668,0.15686281798455382, -1], [0.8381004271849505,1.2006397842313576, -1], [0.05972014277357616,0.16843035538990378, -1], [-0.07080492130900422,1.2611540277056508, -1], [0.7571413277365708,0.1257624271513193, -1], [0.9141564338096521,0.9983917232337024, -1], [-0.3529791124411232,0.19881675379047936, -1], [0.11342282667023776,1.1186212885774436, -1], [0.9495500834027659,0.28495968221932017, -1], [0.7199701918686008,1.0596876127028512, -1], [-0.1398126181123336,-0.14734036688230828, -1], [-0.33078193236744313,1.0515470001748684, -1], [0.7670067490202555,0.011815087417743415, -1], [1.1208649730019724,1.0674770729173093, -1], [0.1567031066305234,-0.2190509083042354, -1], [0.05352127493540262,0.9799625320571286, -1], [0.9239983134981866,0.0786549292591511, -1], [0.8528524235760642,1.0173619402211442, -1], [-0.07526268026364165,0.111242920939206, -1], [0.17314847499407168,0.9820864767540508, -1], [1.0931179086411746,0.05085914467559604, -1], [0.9178719476802523,1.01151119481717, -1], [0.08782274327193627,-0.12111890648507344, -1], [-0.004831305447880668,1.0887997209023026, -1], [0.6193213418061092,0.07194945388299491, -1], [1.0439676279962955,0.8313793132853518, -1], [0.14570615365714307,0.17335624572968666, -1], [-0.12144454974597146,1.0947514977830137, -1], [1.1401231981120117,0.03683649838356402, -1], [0.9819324338230033,0.8290291592101053, -1], [-0.013281277805592625,-0.09871361495439586, -1], [0.20812887861375504,0.9230121728177118, -1], [1.0774526016592023,0.25995566572733425, -1], [0.7964463826025839,1.061942329566654, -1], [-0.06517150242470841,0.08440343996277269, -1], [-0.24363518312692609,0.9171640907434776, -1], [0.9059570968830661,-0.38748536826099833, -1], [1.1827338264308838,1.1046465654112103, -1], [-0.16653514149820106,0.11970476376898265, -1], [-0.09546510622718937,1.1073962006759188, -1], [0.841402062821512,0.01573072368954652, -1], [0.6539227868926758,0.9010413538295707, -1]])

    # Train the neural network using the training set.
    neural_network.train(training_set_inputs_64, training_set_outputs_64, 1000)

    print("Stage 2) New synaptic weights after training: ")
    neural_network.print_weights()

    # Test the neural network with a new situation.
    hidden_state, output = neural_network.think(array([[0,0,-1]]))

    print(output)
